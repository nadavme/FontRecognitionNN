{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finalProject - Font Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMn6WWj9iqRFlDur2YrnxSh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadavme/FontRecognitionNN/blob/main/finalProject_Font_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGvUXzYq1J2S",
        "outputId": "08202e2d-a31b-4248-c67c-1c4389e04450"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEGQdaWWN0i3"
      },
      "source": [
        "# Nadav Meidan \r\n",
        "\r\n",
        "# ------------------imports----------------------------------------------\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torchvision import datasets, transforms\r\n",
        "import numpy as np\r\n",
        "import h5py\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "import gc\r\n",
        "import csv\r\n",
        "\r\n",
        "\r\n",
        "# Filter harmless warnings\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofT8HyhvOZe_"
      },
      "source": [
        "# ------------------Global Variables-------------------------------\r\n",
        "\r\n",
        "#Paths\r\n",
        "\r\n",
        "trainPath = '/content/gdrive/MyDrive/Colab Notebooks/intro2ComputerVision/SynthText.h5'\r\n",
        "validationPath = '/content/gdrive/MyDrive/Colab Notebooks/intro2ComputerVision/SynthText_val.h5'\r\n",
        "testPath = '/content/gdrive/MyDrive/Colab Notebooks/intro2ComputerVision/Final Project/test.h5'\r\n",
        "dataPath = '/content/gdrive/MyDrive/Colab Notebooks/intro2ComputerVision/Data'\r\n",
        "pathToModel = '/content/gdrive/MyDrive/Colab Notebooks/intro2ComputerVision/NadavMeidan-Model.h5'\r\n",
        "pathToCSVfile = '/content/gdrive/MyDrive/Colab Notebooks/intro2ComputerVision/testPredictionsNadavMeidann.csv'\r\n",
        "\r\n",
        "\r\n",
        "# Parameters\r\n",
        "\r\n",
        "max_epochs = 100\r\n",
        "n_epochs = 32\r\n",
        "batch_size_train = 64\r\n",
        "batch_size_test = 1000\r\n",
        "learning_rate = 0.00095\r\n",
        "momentum = 0.9 \r\n",
        "log_interval = 60 \r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Um2HfZyOdqa"
      },
      "source": [
        "#----------------------------------------------------------------------------\r\n",
        "#-------------Train and validation--------------------------------------------\r\n",
        "#----------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zanvD9kOjY5"
      },
      "source": [
        "# ------------------Preprocessing the data-------------------------------\r\n",
        "\r\n",
        "\r\n",
        "def preProcessData(dataPath, charListImgs, charListLables):\r\n",
        "\r\n",
        "    file_name = dataPath\r\n",
        "    db = h5py.File(file_name, 'r')\r\n",
        "    im_names = list(db['data'].keys())\r\n",
        "    # The charList holds tuples of images and their lables\r\n",
        "    \r\n",
        "    for im in im_names:\r\n",
        "        PER = 128\r\n",
        "        # image\r\n",
        "        img = np.array(db['data'][im])\r\n",
        "        # display(img, im)  # debug\r\n",
        "        font = db['data'][im].attrs['font']\r\n",
        "        # chars boxes\r\n",
        "        char_bb = db['data'][im].attrs['charBB']\r\n",
        "        # print('number of char in image = {}'.format(char_bb.shape[2]))\r\n",
        "        for i in range((char_bb.shape[2])):\r\n",
        "\r\n",
        "            # char image - perspective transform\r\n",
        "            pts1 = np.float32([char_bb[:, :, i].T[0], char_bb[:, :, i].T[1], char_bb[:, :, i].T[3], char_bb[:, :, i].T[2]])\r\n",
        "            pts2 = np.float32([[0, 0], [PER, 0], [0, PER], [PER, PER]])\r\n",
        "            if font[i] ==  b'Skylark':\r\n",
        "              lable = 0.0   \r\n",
        "            elif font[i] ==  b'Ubuntu Mono':\r\n",
        "              lable = 1.0 \r\n",
        "            elif font[i] ==  b'Sweet Puppy':\r\n",
        "              lable = 2.0 \r\n",
        "            else:\r\n",
        "              print('something went wrong! in file name = {}'.format(im))\r\n",
        "              exit()\r\n",
        "            m = cv2.getPerspectiveTransform(pts1, pts2)\r\n",
        "            dst = cv2.warpPerspective(img, m, (PER, PER))\r\n",
        "            charListImgs.append(dst)\r\n",
        "            charListLables.append(lable)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txrmpoS1OnR9"
      },
      "source": [
        "def writeToFolder(charListImgs, charListLables, whichData):\r\n",
        "\r\n",
        "    dataPath = '/content/gdrive/MyDrive/Colab Notebooks/intro2ComputerVision/Data'\r\n",
        "    if not os.path.exists(dataPath):\r\n",
        "        os.mkdir(dataPath) \r\n",
        "    \r\n",
        "    if whichData == 'train': \r\n",
        "        PATH = os.path.join(dataPath, 'trainData')\r\n",
        "        if not os.path.exists(PATH):\r\n",
        "          os.mkdir(PATH)\r\n",
        "        os.mkdir(os.path.join(PATH, 'Skylark'))\r\n",
        "        os.mkdir(os.path.join(PATH, 'Ubuntu Mono'))\r\n",
        "        os.mkdir(os.path.join(PATH, 'Sweet Puppy'))\r\n",
        "    \r\n",
        "    if whichData == 'validation': \r\n",
        "        PATH = os.path.join(dataPath, 'valData')\r\n",
        "        if not os.path.exists(PATH):\r\n",
        "            os.mkdir(PATH)\r\n",
        "        os.mkdir(os.path.join(PATH, 'Skylark'))\r\n",
        "        os.mkdir(os.path.join(PATH, 'Ubuntu Mono'))\r\n",
        "        os.mkdir(os.path.join(PATH, 'Sweet Puppy'))\r\n",
        "\r\n",
        "    for i in range(len(charListImgs)):\r\n",
        "        img = charListImgs[i]\r\n",
        "\r\n",
        "        if charListLables[i] ==  0.0:\r\n",
        "          path = os.path.join(PATH, 'Skylark')\r\n",
        "          cv2.imwrite(os.path.join(path , str(i)+ '.jpg'), img)\r\n",
        "        elif charListLables[i] ==  1.0 :\r\n",
        "          path = os.path.join(PATH, 'Ubuntu Mono')\r\n",
        "          cv2.imwrite(os.path.join(path , str(i) + '.jpg'), img) \r\n",
        "        elif charListLables[i] ==  2.0 :\r\n",
        "          path = os.path.join(PATH, 'Sweet Puppy')\r\n",
        "          cv2.imwrite(os.path.join(path , str(i)+ '.jpg'), img)  \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbjzI73UOqzi"
      },
      "source": [
        "def loadTheData(trainPath, validationPath):\r\n",
        "\r\n",
        "    charListImgsTrain = []\r\n",
        "    charListLablesTrain = []\r\n",
        "    charListImgsVal = []\r\n",
        "    charListLablesVal = []\r\n",
        "    \r\n",
        "    preProcessData(trainPath, charListImgsTrain, charListLablesTrain)\r\n",
        "    preProcessData(validationPath, charListImgsVal, charListLablesVal)\r\n",
        "    \r\n",
        "    writeToFolder(charListImgsTrain, charListLablesTrain, 'train')\r\n",
        "    writeToFolder(charListImgsVal, charListLablesVal, 'validation')\r\n",
        "    \r\n",
        "    train_transform = transforms.Compose([\r\n",
        "\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\r\n",
        "                             [0.229, 0.224, 0.225])\r\n",
        "    ])\r\n",
        "\r\n",
        "    validation_transform = transforms.Compose([\r\n",
        "            transforms.ToTensor(),\r\n",
        "            transforms.Normalize([0.485, 0.456, 0.406],\r\n",
        "                                 [0.229, 0.224, 0.225])\r\n",
        "        ])\r\n",
        "    \r\n",
        "    train_data = datasets.ImageFolder(os.path.join(dataPath, 'trainData'), transform=train_transform)\r\n",
        "    validation_data = datasets.ImageFolder(os.path.join(dataPath, 'valData'), transform=validation_transform)\r\n",
        "    \r\n",
        "    torch.manual_seed(42)\r\n",
        "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\r\n",
        "    validation_loader = DataLoader(validation_data, batch_size=64, shuffle=True)\r\n",
        "    \r\n",
        "    \r\n",
        "    return train_loader, validation_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uGxKSM2Otzs"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\r\n",
        "  'Characterizes a dataset for PyTorch'\r\n",
        "  def __init__(self, inputs, labels):\r\n",
        "        'Initialization'\r\n",
        "        self.labels = labels\r\n",
        "        self.inputs = inputs\r\n",
        "        self.make_data_np()\r\n",
        "        # self.make_data_torch()\r\n",
        "\r\n",
        "        self.length = self.inputs_np.shape[0]\r\n",
        "    \r\n",
        " \r\n",
        "  def make_data_np(self):\r\n",
        "      self.inputs_np = np.array(self.inputs)\r\n",
        "      self.inputs_np = np.transpose(self.inputs_np, axes = (0,3,1,2,))\r\n",
        "      self.labels_np = np.array(self.labels)\r\n",
        "      gc.collect()\r\n",
        "  \r\n",
        "  \r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "        'Denotes the total number of samples'\r\n",
        "        return len(self.inputs)\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "        input = torch.tensor(self.inputs_np[index]).type(torch.cuda.FloatTensor)\r\n",
        "        lable = torch.tensor(self.labels_np[index]).type(torch.cuda.FloatTensor)\r\n",
        "        return input, lable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0sLOJ3iOwtn"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(3, 512, kernel_size=3 ,padding = (1,1))\r\n",
        "        self.conv2 = nn.Conv2d(512, 256, kernel_size=3, padding = (1,1))\r\n",
        "        self.conv3 = nn.Conv2d(256, 128, kernel_size=3, padding = (1,1))\r\n",
        "        self.conv2_drop = nn.Dropout2d()\r\n",
        "        self.fc1 = nn.Linear(32768, 64)\r\n",
        "        self.fc2 = nn.Linear(64, 64)\r\n",
        "        self.fc3 = nn.Linear(64, 3)\r\n",
        "        self.batchNorm1 = nn.BatchNorm2d(512)\r\n",
        "        self.batchNorm2 = nn.BatchNorm2d(256)\r\n",
        "        self.batchNorm3 = nn.BatchNorm2d(128)\r\n",
        "        # self.noise = GaussianNoise()\r\n",
        "    def forward(self, x):\r\n",
        "\r\n",
        "        x = F.dropout(F.relu(self.batchNorm1(self.conv1(x))),0.25)\r\n",
        "        x = F.max_pool2d(x , 2)\r\n",
        "        x = F.dropout(F.relu(self.batchNorm2(self.conv2(x))),0.15)\r\n",
        "        x = F.max_pool2d(x , 2)\r\n",
        "        x = F.dropout(F.relu(self.batchNorm3(self.conv3(x))),0.3)\r\n",
        "        x = F.max_pool2d(x , 2)\r\n",
        "        x = x.view(-1, 32768)\r\n",
        "        x = F.dropout(F.relu(self.fc1(x)),0.4)\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = self.fc3(x)\r\n",
        "        return F.log_softmax(x)\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hERxPCx-O0kz"
      },
      "source": [
        "def train(network, epoch, train_loader, optimizer):\r\n",
        "    #For analizing the model\r\n",
        "    train_losses = []\r\n",
        "    train_counter = []\r\n",
        "    test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\r\n",
        "\r\n",
        "\r\n",
        "    network.train()\r\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\r\n",
        "        data = data.to(device='cuda')\r\n",
        "        target = target.to(device='cuda')\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        output = network(data)\r\n",
        "        loss = F.nll_loss(output, target.long())\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        if batch_idx % log_interval == 0:\r\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\r\n",
        "              epoch, batch_idx * len(data), len(train_loader.dataset),\r\n",
        "              100. * batch_idx / len(train_loader), loss.item()))\r\n",
        "            train_losses.append(loss.item())\r\n",
        "            train_counter.append(\r\n",
        "            (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N34nt-CuO5ed"
      },
      "source": [
        "def valid(network, validation_loader):\r\n",
        "    #For analizing the model\r\n",
        "    validation_losses = []\r\n",
        "    accuracy_counter = []\r\n",
        "    \r\n",
        "    network.eval()\r\n",
        "    validation_loss = 0\r\n",
        "    correct = 0\r\n",
        "    with torch.no_grad():\r\n",
        "      for data, target in validation_loader:\r\n",
        "        data = data.to(device='cuda')\r\n",
        "        target = target.to(device='cuda')\r\n",
        "        output = network(data)\r\n",
        "        validation_loss += F.nll_loss(output, target.long(), size_average=False).item()\r\n",
        "        pred = output.data.max(1, keepdim=True)[1]\r\n",
        "        correct += pred.eq(target.data.view_as(pred)).sum()\r\n",
        "    validation_loss /= len(validation_loader.dataset)\r\n",
        "    validation_losses.append(validation_loss)\r\n",
        "    print('\\nValidation set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\r\n",
        "      validation_loss, correct, len(validation_loader.dataset),\r\n",
        "      100. * correct / len(validation_loader.dataset)))\r\n",
        "    accuracy_counter.append(100. * correct / len(validation_loader.dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNiDq0g3O8l2"
      },
      "source": [
        "def trainTheModel(network, train_loader, validation_loader, optimizer):\r\n",
        "    #Add the perproccesing of the data and network\r\n",
        "    #Send all the network, loader and shit\r\n",
        "    for epoch in range(1, n_epochs + 1):\r\n",
        "      train(network,epoch, train_loader, optimizer)\r\n",
        "      valid(network, validation_loader)\r\n",
        "      torch.save(network.state_dict(), '/content/gdrive/MyDrive/Colab Notebooks/intro2ComputerVision/myTrainedModelSugar.h5')\r\n",
        "\r\n",
        "\r\n",
        "def trainAndValidateModel(network, trainPath, validationPat):\r\n",
        "    train_loader, validation_loader = loadTheData(trainPath, validationPath)\r\n",
        "    if torch.cuda.is_available():\r\n",
        "      network.cuda()\r\n",
        "    optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate,\r\n",
        "                          momentum=momentum)\r\n",
        "    trainTheModel(network, train_loader, validation_loader, optimizer)\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28OPQGU5O_us"
      },
      "source": [
        "#----------------------------------------------------------------------------\r\n",
        "#-------------Train and validation--------------------------------------------\r\n",
        "#----------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za8JQIfjPCf8"
      },
      "source": [
        "#-----------------------Utils fuctions----------------------------------------\r\n",
        "\r\n",
        "def writeBatchToCSV(predictionsPerWord, counterCSV, pathToCSVfile, word, im):\r\n",
        "  with open(pathToCSVfile, 'a', newline='') as file:\r\n",
        "      writer = csv.writer(file)\r\n",
        "      for k in range(len(predictionsPerWord)):\r\n",
        "            counterCSV += 1\r\n",
        "            # print(counterCSV)\r\n",
        "          # print(word[k])\r\n",
        "            if predictionsPerWord[k] ==  0:\r\n",
        "                writer.writerow([counterCSV, im, word[k], \"1.0\", \"0.0\", \"0.0\"])\r\n",
        "            elif predictionsPerWord[k] ==  1:\r\n",
        "                writer.writerow([counterCSV, im, word[k], \"0.0\", \"1.0\", \"0.0\"])\r\n",
        "            elif predictionsPerWord[k] ==  2:\r\n",
        "                writer.writerow([str(counterCSV), im, word[k], \"0.0\", \"0.0\", \"1.0\"])\r\n",
        "      return counterCSV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDRSMAs0PG0s"
      },
      "source": [
        "# Function to find most frequent element in a list \r\n",
        "def most_frequent(List): \r\n",
        "    return max(set(List), key = List.count) \r\n",
        "\r\n",
        "\r\n",
        "def validatePredictions(predictionsPerWord): \r\n",
        "  #Here i use the facr that any char in the word has the same font.\r\n",
        "      most = most_frequent(predictionsPerWord)\r\n",
        "      for i in range(len(predictionsPerWord)):\r\n",
        "        if predictionsPerWord[i] != most:\r\n",
        "          predictionsPerWord[i] = most\r\n",
        "      return predictionsPerWord\r\n",
        "\r\n",
        "def prdeictChar(network, input):\r\n",
        "      with torch.no_grad():\r\n",
        "        # make sure of the device type\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            input = input.to(device='cuda')\r\n",
        "            network.cuda()\r\n",
        "        # print(input.shape)\r\n",
        "        output = network(input)\r\n",
        "        prediction = output.data.max(1, keepdim=True)[1]\r\n",
        "        # print('output:' , output, 'pred: ', prediction)\r\n",
        "        return prediction.item()\r\n",
        "\r\n",
        "def loadToNetwork(batchChars, network):\r\n",
        "      test_transform = transforms.Compose([\r\n",
        "              transforms.ToTensor(),\r\n",
        "              transforms.Normalize([0.485, 0.456, 0.406],\r\n",
        "                                  [0.229, 0.224, 0.225])\r\n",
        "              ])\r\n",
        "      # print('iam batchChars:', batchChars[-1].shape)\r\n",
        "      predictions = []\r\n",
        "      for char in batchChars:\r\n",
        "          char = test_transform(char)\r\n",
        "          char = char.view(1, 3, 128, 128)\r\n",
        "          predictions.append(prdeictChar(network, char))\r\n",
        "      return predictions\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghtXncFSPJ9-"
      },
      "source": [
        "#-----------------------Flow fuction of the test--------------------------------\r\n",
        "\r\n",
        "def testTheModel(network, testPath):\r\n",
        "    file_name = testPath\r\n",
        "    db = h5py.File(file_name, 'r')\r\n",
        "    # The testImagesNamesList holds tuples of images\r\n",
        "    testImagesNamesList = list(db['data'].keys())\r\n",
        "    \r\n",
        "    with open(pathToCSVfile, 'w', newline='') as file:\r\n",
        "        writer = csv.writer(file)\r\n",
        "        writer.writerow([\"SN\", \"image\", \"Char\", \"b'Skylark'\", \"b'Sweet Puppy'\", \"b'Ubuntu Mono'\"])\r\n",
        "    \r\n",
        "    network.load_state_dict(torch.load(pathToModel))\r\n",
        "    network.eval()\r\n",
        "    counterCSV = 0;\r\n",
        "    for im in testImagesNamesList:\r\n",
        "        \r\n",
        "        counter = 0\r\n",
        "        PER = 128 #An image of 128*128 pixels\r\n",
        "        img = np.array(db['data'][im])# image\r\n",
        "        # chars boxes\r\n",
        "        char_bb = db['data'][im].attrs['charBB']\r\n",
        "        ammountOfWordsInImage = db['data'][im].attrs['wordBB'].shape[2]\r\n",
        "        wordsInImage = list(db['data'][im].attrs['txt'])\r\n",
        "        \r\n",
        "        for i in range(ammountOfWordsInImage):\r\n",
        "          word = wordsInImage[i].decode('utf-8')\r\n",
        "          batchChars = []\r\n",
        "          \r\n",
        "          for j in range(len(word)):\r\n",
        "              # char image - perspective transform\r\n",
        "              pts1 = np.float32([char_bb[:, :, counter].T[0], char_bb[:, :, counter].T[1], char_bb[:, :, counter].T[3], char_bb[:, :, counter].T[2]])\r\n",
        "              pts2 = np.float32([[0, 0], [PER, 0], [0, PER], [PER, PER]])\r\n",
        "    \r\n",
        "              m = cv2.getPerspectiveTransform(pts1, pts2)\r\n",
        "              dst = cv2.warpPerspective(img, m, (PER, PER))\r\n",
        "              \r\n",
        "              counter += 1\r\n",
        "              batchChars.append(dst)\r\n",
        "\r\n",
        "        #Predict a a font of one word from the image at a time.\r\n",
        "          predictionsPerBatch = loadToNetwork(batchChars, network)\r\n",
        "          validatedPredictions = validatePredictions(predictionsPerBatch)\r\n",
        "          counterCSV = writeBatchToCSV(validatedPredictions, counterCSV, pathToCSVfile, word, im)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMvnbfXwPRrg"
      },
      "source": [
        "def main():\r\n",
        "    # useGpu()\r\n",
        "    network = Net()\r\n",
        "    # trainAndValidateModel(network, trainPath, validationPath)\r\n",
        "    testTheModel(network, testPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG2o9aBYIDS9",
        "outputId": "83d47d47-c3b4-4d4a-bee5-cb0b231fe047"
      },
      "source": [
        "network.cuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.cuda of Net(\n",
              "  (conv1): Conv2d(3, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=32768, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=3, bias=True)\n",
              "  (batchNorm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batchNorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batchNorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1Vl8OPnxbT9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4711b5-a7be-40b1-f7f3-52cc3fcd1777"
      },
      "source": [
        "for epoch in range(1, n_epochs + 1):\r\n",
        "  train(epoch)\r\n",
        "  valid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/12237 (0%)]\tLoss: 0.024389\n",
            "Train Epoch: 1 [6400/12237 (52%)]\tLoss: 0.084215\n",
            "\n",
            "Test set: Avg. loss: 0.2338, Accuracy: 7667/8197 (94%)\n",
            "\n",
            "Train Epoch: 2 [0/12237 (0%)]\tLoss: 0.022183\n",
            "Train Epoch: 2 [6400/12237 (52%)]\tLoss: 0.060814\n",
            "\n",
            "Test set: Avg. loss: 0.2130, Accuracy: 7681/8197 (94%)\n",
            "\n",
            "Train Epoch: 3 [0/12237 (0%)]\tLoss: 0.019960\n",
            "Train Epoch: 3 [6400/12237 (52%)]\tLoss: 0.069853\n",
            "\n",
            "Test set: Avg. loss: 0.2248, Accuracy: 7694/8197 (94%)\n",
            "\n",
            "Train Epoch: 4 [0/12237 (0%)]\tLoss: 0.035262\n",
            "Train Epoch: 4 [6400/12237 (52%)]\tLoss: 0.046278\n",
            "\n",
            "Test set: Avg. loss: 0.2364, Accuracy: 7663/8197 (93%)\n",
            "\n",
            "Train Epoch: 5 [0/12237 (0%)]\tLoss: 0.053450\n",
            "Train Epoch: 5 [6400/12237 (52%)]\tLoss: 0.024364\n",
            "\n",
            "Test set: Avg. loss: 0.2284, Accuracy: 7679/8197 (94%)\n",
            "\n",
            "Train Epoch: 6 [0/12237 (0%)]\tLoss: 0.063292\n",
            "Train Epoch: 6 [6400/12237 (52%)]\tLoss: 0.024870\n",
            "\n",
            "Test set: Avg. loss: 0.2312, Accuracy: 7702/8197 (94%)\n",
            "\n",
            "Train Epoch: 7 [0/12237 (0%)]\tLoss: 0.039635\n",
            "Train Epoch: 7 [6400/12237 (52%)]\tLoss: 0.048735\n",
            "\n",
            "Test set: Avg. loss: 0.2291, Accuracy: 7667/8197 (94%)\n",
            "\n",
            "Train Epoch: 8 [0/12237 (0%)]\tLoss: 0.007767\n",
            "Train Epoch: 8 [6400/12237 (52%)]\tLoss: 0.052616\n",
            "\n",
            "Test set: Avg. loss: 0.2552, Accuracy: 7659/8197 (93%)\n",
            "\n",
            "Train Epoch: 9 [0/12237 (0%)]\tLoss: 0.002882\n",
            "Train Epoch: 9 [6400/12237 (52%)]\tLoss: 0.024615\n",
            "\n",
            "Test set: Avg. loss: 0.2658, Accuracy: 7677/8197 (94%)\n",
            "\n",
            "Train Epoch: 10 [0/12237 (0%)]\tLoss: 0.008056\n",
            "Train Epoch: 10 [6400/12237 (52%)]\tLoss: 0.066330\n",
            "\n",
            "Test set: Avg. loss: 0.2321, Accuracy: 7675/8197 (94%)\n",
            "\n",
            "Train Epoch: 11 [0/12237 (0%)]\tLoss: 0.023342\n",
            "Train Epoch: 11 [6400/12237 (52%)]\tLoss: 0.039438\n",
            "\n",
            "Test set: Avg. loss: 0.2407, Accuracy: 7685/8197 (94%)\n",
            "\n",
            "Train Epoch: 12 [0/12237 (0%)]\tLoss: 0.022870\n",
            "Train Epoch: 12 [6400/12237 (52%)]\tLoss: 0.032638\n",
            "\n",
            "Test set: Avg. loss: 0.2628, Accuracy: 7692/8197 (94%)\n",
            "\n",
            "Train Epoch: 13 [0/12237 (0%)]\tLoss: 0.030861\n",
            "Train Epoch: 13 [6400/12237 (52%)]\tLoss: 0.014612\n",
            "\n",
            "Test set: Avg. loss: 0.2975, Accuracy: 7682/8197 (94%)\n",
            "\n",
            "Train Epoch: 14 [0/12237 (0%)]\tLoss: 0.016862\n",
            "Train Epoch: 14 [6400/12237 (52%)]\tLoss: 0.010902\n",
            "\n",
            "Test set: Avg. loss: 0.2309, Accuracy: 7718/8197 (94%)\n",
            "\n",
            "Train Epoch: 15 [0/12237 (0%)]\tLoss: 0.008106\n",
            "Train Epoch: 15 [6400/12237 (52%)]\tLoss: 0.004579\n",
            "\n",
            "Test set: Avg. loss: 0.2412, Accuracy: 7706/8197 (94%)\n",
            "\n",
            "Train Epoch: 16 [0/12237 (0%)]\tLoss: 0.028270\n",
            "Train Epoch: 16 [6400/12237 (52%)]\tLoss: 0.042663\n",
            "\n",
            "Test set: Avg. loss: 0.2504, Accuracy: 7697/8197 (94%)\n",
            "\n",
            "Train Epoch: 17 [0/12237 (0%)]\tLoss: 0.042684\n",
            "Train Epoch: 17 [6400/12237 (52%)]\tLoss: 0.045190\n",
            "\n",
            "Test set: Avg. loss: 0.2332, Accuracy: 7719/8197 (94%)\n",
            "\n",
            "Train Epoch: 18 [0/12237 (0%)]\tLoss: 0.024625\n",
            "Train Epoch: 18 [6400/12237 (52%)]\tLoss: 0.044602\n",
            "\n",
            "Test set: Avg. loss: 0.2558, Accuracy: 7678/8197 (94%)\n",
            "\n",
            "Train Epoch: 19 [0/12237 (0%)]\tLoss: 0.030948\n",
            "Train Epoch: 19 [6400/12237 (52%)]\tLoss: 0.006102\n",
            "\n",
            "Test set: Avg. loss: 0.2581, Accuracy: 7702/8197 (94%)\n",
            "\n",
            "Train Epoch: 20 [0/12237 (0%)]\tLoss: 0.042583\n",
            "Train Epoch: 20 [6400/12237 (52%)]\tLoss: 0.034474\n",
            "\n",
            "Test set: Avg. loss: 0.2523, Accuracy: 7699/8197 (94%)\n",
            "\n",
            "Train Epoch: 21 [0/12237 (0%)]\tLoss: 0.002296\n",
            "Train Epoch: 21 [6400/12237 (52%)]\tLoss: 0.054002\n",
            "\n",
            "Test set: Avg. loss: 0.2473, Accuracy: 7702/8197 (94%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}